{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries \n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We want to analysis NaN's specifically in the dietary dataset so we can understand what is missing in our modeling and what exactly to focus on for features as well as remove/input NaN's to increase accuracy in our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "file_path = '/Users/aakashsuresh/fairness/processed_data_new/nhanes_combined_diet.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape: (19931, 39)\n",
      "Initial missing values:\n",
      " SEQN            0\n",
      "DSDCOUNT        0\n",
      "DSDANCNT        0\n",
      "DSD010          0\n",
      "DSD010AN        0\n",
      "DSQTKCAL    15892\n",
      "DSQTPROT    19546\n",
      "DSQTCARB    17054\n",
      "DSQTSUGR    17241\n",
      "DSQTFIBE    19679\n",
      "DSQTTFAT    18513\n",
      "DSQTSFAT    19539\n",
      "DSQTMFAT    19770\n",
      "DSQTPFAT    19265\n",
      "DSQTCHOL    19036\n",
      "DSQTLYCO    18638\n",
      "DSQTLZ      18639\n",
      "DSQTVB1     16044\n",
      "DSQTVB2     16032\n",
      "DSQTNIAC    15861\n",
      "DSQTVB6     14769\n",
      "DSQTFA      14892\n",
      "DSQTFDFE    14892\n",
      "DSQTCHL     18340\n",
      "DSQTVB12    14552\n",
      "DSQTVC      14165\n",
      "DSQTVK      17342\n",
      "DSQTVD      13807\n",
      "DSQTCALC    14860\n",
      "DSQTPHOS    17980\n",
      "DSQTMAGN    16155\n",
      "DSQTIRON    17473\n",
      "DSQTZINC    15187\n",
      "DSQTCOPP    16603\n",
      "DSQTSODI    18533\n",
      "DSQTPOTA    17987\n",
      "DSQTSELE    17117\n",
      "DSQTCAFF    19894\n",
      "DSQTIODI    16323\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display information about the dataset \n",
    "print(\"Initial dataset shape:\", df.shape)\n",
    "print(\"Initial missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we can see that there are many missing values in this dataset, taken from some research through the CDC: As a general guideline, if 10% or less of the main outcome variable's data are missing, the dataset is typically considered acceptable for analysis without further adjustments. So we will filter our data if they are missing 10% of values or lower. We will also go through some general filtering processes, for example, if the columns are missing participant ID's or etc. we will also drop them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape after removing columns with >10% missing values: (19931, 5)\n"
     ]
    }
   ],
   "source": [
    "# 1. Remove columns with more than 10% missing values\n",
    "threshold = 0.10\n",
    "df = df.loc[:, df.isnull().mean() < threshold]\n",
    "print(\"\\nShape after removing columns with >10% missing values:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SEQN', 'DSDCOUNT', 'DSDANCNT', 'DSD010', 'DSD010AN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape after dropping rows with missing critical values: (19931, 5)\n"
     ]
    }
   ],
   "source": [
    "# 2. Drop rows with missing values in critical columns (e.g., 'participant_id')\n",
    "critical_columns = ['SEQN', 'DSDCOUNT', 'DSDANCNT', 'DSD010', 'DSD010AN']  # Replace with actual critical columns\n",
    "df = df.dropna(subset=critical_columns)\n",
    "print(\"\\nShape after dropping rows with missing critical values:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After dropping any missing columns, we want to impute these rows with numerical and categorical variables to allow for modeling to occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Impute remaining missing values\n",
    "# Separate numerical and categorical columns\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute numerical columns with mean\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "df[numerical_cols] = num_imputer.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After going through the dataset, I thought there was no categorical variables so just wanted to write the function below to analyze if there were any of these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No categorical columns found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "# Ensure categorical_cols is not empty\n",
    "if len(categorical_cols) > 0:\n",
    "    cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    # Ensure the DataFrame is not empty before applying transformation\n",
    "    if not df[categorical_cols].empty:\n",
    "        df[categorical_cols] = cat_imputer.fit_transform(df[categorical_cols])\n",
    "    else:\n",
    "        print(\"No categorical data available for imputation.\")\n",
    "else:\n",
    "    print(\"No categorical columns found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since there are no categorical features we want to normalize our numerical features so we can use it for our modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset shape: (19931, 5)\n",
      "Final missing values:\n",
      " 0\n"
     ]
    }
   ],
   "source": [
    "# Display final information\n",
    "print(\"\\nFinal dataset shape:\", df.shape)\n",
    "print(\"Final missing values:\\n\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset saved to /Users/aakashsuresh/fairness/processed_data_new/cleaned_nhanes_combined_diet.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "output_path = '/Users/aakashsuresh/fairness/processed_data_new/cleaned_nhanes_combined_diet.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nCleaned dataset saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Analysis and Identification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After looking at these NaN values, we want to analyze and see if there are any labels outside of glucose in diet to make our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible labels to consider\n",
    "potential_labels = {\n",
    "    \"Diabetes\": [\"glucose\", \"HbA1c\", \"insulin_levels\"],\n",
    "    \"Mental Health\": [\"mental_health\", \"stress_level\", \"sleep_hours\"],\n",
    "    \"Lifestyle\": [\"exercise_frequency\", \"diet_quality\", \"smoking_status\", \"alcohol_intake\"],\n",
    "    \"Vital Signs\": [\"heart_rate\", \"blood_pressure\", \"BMI\", \"cholesterol\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which of these labels exist in the dataset\n",
    "identified_labels = {category: [col for col in columns if col in df.columns] \n",
    "                     for category, columns in potential_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified relevant labels in the dataset:\n",
      "- Diabetes: No matching labels found\n",
      "- Mental Health: No matching labels found\n",
      "- Lifestyle: No matching labels found\n",
      "- Vital Signs: No matching labels found\n"
     ]
    }
   ],
   "source": [
    "# Print identified labels\n",
    "print(\"Identified relevant labels in the dataset:\")\n",
    "for category, labels in identified_labels.items():\n",
    "    if labels:\n",
    "        print(f\"- {category}: {', '.join(labels)}\")\n",
    "    else:\n",
    "        print(f\"- {category}: No matching labels found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No matching labels found through this process so going to use fuzzy matching to identify labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakashsuresh/.pyenv/versions/3.10.12/lib/python3.10/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keywords for label identification\n",
    "label_keywords = {\n",
    "    \"Diabetes\": [\"glucose\", \"sugar\", \"insulin\", \"hba1c\", \"diabetes\"],\n",
    "    \"Mental Health\": [\"stress\", \"anxiety\", \"depression\", \"mental\", \"sleep\"],\n",
    "    \"Lifestyle\": [\"exercise\", \"diet\", \"smoking\", \"alcohol\", \"activity\"],\n",
    "    \"Vital Signs\": [\"heart\", \"blood_pressure\", \"bmi\", \"cholesterol\", \"pulse\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuzzy matching function\n",
    "def find_matching_columns(df_columns, keywords):\n",
    "    matched = []\n",
    "    for keyword in keywords:\n",
    "        # Extract best match and score\n",
    "        match = process.extractOne(keyword, df_columns, score_cutoff=40) \n",
    "        if match:  # Ensure that a valid match is found\n",
    "            matched.append(match[0])  # Append only the column name\n",
    "    return list(set(matched))  # Remove duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are some matching labels that are present when doing fuzzy matching, but still the next step for the next week should most likely be feature engineering for new labels in modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified relevant labels in the dataset:\n",
      "- Diabetes: SEQN\n",
      "- Mental Health: SEQN, DSDANCNT\n",
      "- Lifestyle: SEQN, DSDCOUNT\n",
      "- Vital Signs: SEQN\n"
     ]
    }
   ],
   "source": [
    "# Identify relevant labels in dataset\n",
    "identified_labels = {category: find_matching_columns(df.columns, keywords) \n",
    "                     for category, keywords in label_keywords.items()}\n",
    "\n",
    "# Print identified labels\n",
    "print(\"Identified relevant labels in the dataset:\")\n",
    "for category, labels in identified_labels.items():\n",
    "    if labels:\n",
    "        print(f\"- {category}: {', '.join(labels)}\")\n",
    "    else:\n",
    "        print(f\"- {category}: No matching labels found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
