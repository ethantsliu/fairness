{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_merge(data_dir, lab_files, demo_path):\n",
    "    # 1) load each lab file\n",
    "    labs = {}\n",
    "    for fn in lab_files:\n",
    "        key = fn.replace(\"_processed.csv\", \"\")\n",
    "        df = pd.read_csv(os.path.join(data_dir, fn))\n",
    "        print(f\"→ {key}: {df.shape[0]} rows\")\n",
    "        labs[key] = df\n",
    "\n",
    "    # drop empty questionnaire early\n",
    "    labs.pop(\"fasting_questionnaire\", None)\n",
    "\n",
    "    # 2) inner‐merge all labs on seqn\n",
    "    merged = None\n",
    "    for df in labs.values():\n",
    "        merged = df if merged is None else merged.merge(df, on=\"seqn\", how=\"inner\")\n",
    "    print(f\"Merged labs: {merged.shape}\")\n",
    "\n",
    "    # 3) drop any leftover NaNs\n",
    "    merged = merged.dropna()\n",
    "    print(f\"After dropna: {merged.shape}\")\n",
    "\n",
    "    # 4) bring in demographics\n",
    "    demo = pd.read_sas(demo_path, format=\"xport\")[[\"SEQN\", \"RIDAGEYR\", \"RIAGENDR\"]]\n",
    "    demo.columns = demo.columns.str.lower()\n",
    "    merged.columns = merged.columns.str.lower()\n",
    "    merged = merged.merge(demo, on=\"seqn\", how=\"left\")\n",
    "    merged.rename(columns={\"ridageyr\": \"age\", \"riagendr\": \"gender\"}, inplace=True)\n",
    "\n",
    "    print(\"Cols after demo:\", merged.columns.tolist())\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # drop any lab columns you know you won't use\n",
    "    drop_cols = [\n",
    "        \"lbxhcot\", \"lbxhscrp\", \"lbxirn\", \"lbdirnsi\", \"lbxuib\", \"lbdglusi\",\n",
    "        # add more if desired...\n",
    "    ]\n",
    "    for c in drop_cols:\n",
    "        if c in df.columns:\n",
    "            df = df.drop(columns=c)\n",
    "\n",
    "    # define X & y\n",
    "    X = df[[\"age\", \"gender\", \"wtsafprp\"]].copy()\n",
    "    y = df[[\"lbxglu\", \"lbxgh\"]].copy()\n",
    "\n",
    "    # impute without chained‐assignment\n",
    "    for col in X.columns:\n",
    "        if pd.api.types.is_numeric_dtype(X[col]):\n",
    "            X[col] = X[col].fillna(X[col].median())\n",
    "        else:\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_and_evaluate(X, y, do_grid=False):\n",
    "    # split\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # scale X\n",
    "    sx = StandardScaler().fit(Xtr)\n",
    "    Xtr_s = sx.transform(Xtr)\n",
    "    Xte_s = sx.transform(Xte)\n",
    "\n",
    "    # scale y on train only (so we can invert)\n",
    "    sy = StandardScaler().fit(ytr)\n",
    "    ytr_s = sy.transform(ytr)\n",
    "\n",
    "    # base model\n",
    "    base = RandomForestRegressor(random_state=42)\n",
    "    model = MultiOutputRegressor(base)\n",
    "\n",
    "    if do_grid:\n",
    "        grid = {\n",
    "            \"estimator__n_estimators\": [50,100,150],\n",
    "            \"estimator__max_depth\":    [None,5,10],\n",
    "            \"estimator__min_samples_split\": [2,5],\n",
    "            \"estimator__min_samples_leaf\":  [1,2],\n",
    "        }\n",
    "        gs = GridSearchCV(model, grid, cv=5,\n",
    "                          scoring=\"neg_mean_squared_error\",\n",
    "                          n_jobs=-1, verbose=1)\n",
    "        gs.fit(Xtr_s, ytr_s)\n",
    "        model = gs.best_estimator_\n",
    "        print(\"Best params:\", gs.best_params_)\n",
    "    else:\n",
    "        model.fit(Xtr_s, ytr_s)\n",
    "\n",
    "    # predict (scaled), then invert to original\n",
    "    y_pred_s = model.predict(Xte_s)\n",
    "    y_pred   = sy.inverse_transform(y_pred_s)\n",
    "\n",
    "    # also scale y_test for “pure” scaled‐space metrics\n",
    "    yte_s = sy.transform(yte)\n",
    "\n",
    "    # metrics in original mg/dL units\n",
    "    mse_orig = mean_squared_error(yte, y_pred)\n",
    "    mae_orig = mean_absolute_error(yte, y_pred)\n",
    "\n",
    "    # metrics in scaled‐space\n",
    "    mse_s    = mean_squared_error(yte_s, y_pred_s)\n",
    "    mae_s    = mean_absolute_error(yte_s, y_pred_s)\n",
    "\n",
    "    print(\"\\n=== Original‐unit metrics ===\")\n",
    "    print(f\"MSE   : {mse_orig:.3f}  (mg/dL²)\")\n",
    "    print(f\"MAE   : {mae_orig:.3f}  (mg/dL)\")\n",
    "\n",
    "    print(\"\\n=== Scaled‐unit metrics ===\")\n",
    "    print(f\"MSE_s : {mse_s:.3f}\")\n",
    "    print(f\"MAE_s : {mae_s:.3f}\")\n",
    "\n",
    "    return model, sx, sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ fasting_questionnaire: 0 rows\n",
      "→ fasting_glucose: 4744 rows\n",
      "→ glycohemoglobin: 9737 rows\n",
      "→ biochemistry_profile: 9258 rows\n",
      "→ iron_status: 9453 rows\n",
      "→ c_reactive_protein: 11614 rows\n",
      "→ cotinine: 11395 rows\n",
      "Merged labs: (4526, 59)\n",
      "After dropna: (4526, 59)\n",
      "Cols after demo: ['seqn', 'wtsafprp', 'lbxglu', 'lbdglusi', 'lbxgh', 'lbxsatsi', 'lbdsatlc', 'lbxsal', 'lbdsalsi', 'lbxsapsi', 'lbxsassi', 'lbxsc3si', 'lbxsbu', 'lbdsbusi', 'lbxsclsi', 'lbxsck', 'lbxscr', 'lbdscrsi', 'lbxsgb', 'lbdsgbsi', 'lbxsgl', 'lbdsglsi', 'lbxsgtsi', 'lbdsgtlc', 'lbxsir', 'lbdsirsi', 'lbxsldsi', 'lbxsossi', 'lbxsph', 'lbdsphsi', 'lbxsksi', 'lbxsnasi', 'lbxstb', 'lbdstbsi', 'lbdstblc', 'lbxsca', 'lbdscasi', 'lbxsch', 'lbdschsi', 'lbxstp', 'lbdstpsi', 'lbxstr', 'lbdstrsi', 'lbxsua', 'lbdsuasi', 'lbxirn', 'lbdirnsi', 'lbxuib', 'lbduiblc', 'lbduibsi', 'lbdtib', 'lbdtibsi', 'lbdpct', 'lbxhscrp', 'lbdhrplc', 'lbxcot', 'lbdcotlc', 'lbxhcot', 'lbdhcolc', 'age', 'gender']\n",
      "\n",
      "=== Original‐unit metrics ===\n",
      "MSE   : 828.321  (mg/dL²)\n",
      "MAE   : 11.112  (mg/dL)\n",
      "\n",
      "=== Scaled‐unit metrics ===\n",
      "MSE_s : 1.304\n",
      "MAE_s : 0.629\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    data_dir = \"/Users/aakashsuresh/fairness/processed_data_nhanes_lab/\"\n",
    "    lab_files = [\n",
    "        \"fasting_questionnaire_processed.csv\",\n",
    "        \"fasting_glucose_processed.csv\",\n",
    "        \"glycohemoglobin_processed.csv\",\n",
    "        \"biochemistry_profile_processed.csv\",\n",
    "        \"iron_status_processed.csv\",\n",
    "        \"c_reactive_protein_processed.csv\",\n",
    "        \"cotinine_processed.csv\",\n",
    "    ]\n",
    "    demo_path = \"P_DEMO.xpt\"\n",
    "\n",
    "    df = load_and_merge(data_dir, lab_files, demo_path)\n",
    "    X, y = preprocess(df)\n",
    "    train_and_evaluate(X, y, do_grid=False)  # flip to True to tune\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
